#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import json
import sys
import glob
import argparse
import logging
import time
from pathlib import Path
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import pandas as pd
import numpy as np
import jieba
import jieba.posseg as pseg

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ProgressBar:
    """è¿›åº¦æ¡ç±»"""
    def __init__(self, total, prefix='', suffix='', length=50, fill='â–ˆ', empty='â–‘', color=True):
        self.total = total
        self.prefix = prefix
        self.suffix = suffix
        self.length = length
        self.fill = fill
        self.empty = empty
        self.color = color
        self.start_time = time.time()
        self.count = 0
        
    def update(self, count=None):
        """æ›´æ–°è¿›åº¦æ¡"""
        if count is not None:
            self.count = count
        else:
            self.count += 1
            
        percent = self.count / self.total
        filled_length = int(self.length * percent)
        bar = self.fill * filled_length + self.empty * (self.length - filled_length)
        
        # è®¡ç®—å‰©ä½™æ—¶é—´
        elapsed_time = time.time() - self.start_time
        if percent > 0:
            eta = elapsed_time / percent * (1 - percent)
            time_info = f" | {self._format_time(elapsed_time)}<{self._format_time(eta)}"
        else:
            time_info = ""
            
        # å¸¦é¢œè‰²çš„è¿›åº¦æ¡
        if self.color:
            color_code = '\033[92m'  # ç»¿è‰²
            if percent < 0.3:
                color_code = '\033[94m'  # è“è‰²
            elif percent < 0.7:
                color_code = '\033[93m'  # é»„è‰²
            reset_code = '\033[0m'
            bar = f"{color_code}{bar}{reset_code}"
            
        # æ‰“å°è¿›åº¦æ¡
        sys.stdout.write(f"\r{self.prefix} |{bar}| {int(percent * 100)}%{time_info} {self.suffix}")
        sys.stdout.flush()
        
        # å®Œæˆæ—¶æ¢è¡Œ
        if self.count >= self.total:
            sys.stdout.write('\n')
            sys.stdout.flush()
            
    def _format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        m, s = divmod(int(seconds), 60)
        h, m = divmod(m, 60)
        if h > 0:
            return f"{h:d}h{m:02d}m"
        elif m > 0:
            return f"{m:d}m{s:02d}s"
        else:
            return f"{s:d}s"

class GenderStereotypeAnalyzer:
    def __init__(self, config_file=None):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.male_keywords = set()
        self.female_keywords = set()
        self.stopwords = set()
        self.adjective_pos_tags = set()
        self.window_size = 3
        self.font_path = None
        
        if config_file:
            self.load_config(config_file)
        else:
            self.load_default_config()
    
    def load_config(self, config_file):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                self.male_keywords = set(config.get('male_keywords', []))
                self.female_keywords = set(config.get('female_keywords', []))
                self.stopwords = set(config.get('stopwords', []))
                self.adjective_pos_tags = set(config.get('adjective_pos_tags', []))
                self.window_size = config.get('window_size', 3)
                self.font_path = config.get('font_path', 'simhei.ttf')
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            self.load_default_config()
    
    def load_default_config(self):
        """åŠ è½½é»˜è®¤é…ç½®"""
        try:
            config_path = os.path.join(os.path.dirname(__file__), 'config.json')
            self.load_config(config_path)
        except Exception as e:
            logger.error(f"åŠ è½½é»˜è®¤é…ç½®å¤±è´¥: {e}")
            # ä½¿ç”¨ç¡¬ç¼–ç çš„é»˜è®¤å€¼
            self.male_keywords = {'ä»–', 'çˆ¶äº²', 'å„¿å­', 'å…„å¼Ÿ', 'ç”·äºº', 'å…ˆç”Ÿ', 'ç”·å­©'}
            self.female_keywords = {'å¥¹', 'æ¯äº²', 'å¥³å„¿', 'å§å¦¹', 'å¥³äºº', 'å¥³å£«', 'å¥³å­©'}
            self.stopwords = {'çš„', 'äº†', 'å’Œ', 'æ˜¯', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'ä¸', 'ç€',
                            'æˆ–', 'ä¸€ä¸ª', 'æ²¡æœ‰', 'è¿™ä¸ª', 'é‚£ä¸ª', 'è¿™æ ·', 'é‚£æ ·'}
            self.adjective_pos_tags = {'a', 'ad', 'an'}
            self.window_size = 3
            self.font_path = 'simhei.ttf'
    
    def save_config(self, config_file):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            config = {
                'male_keywords': list(self.male_keywords),
                'female_keywords': list(self.female_keywords),
                'stopwords': list(self.stopwords),
                'adjective_pos_tags': list(self.adjective_pos_tags),
                'window_size': self.window_size,
                'font_path': self.font_path
            }
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=4)
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    def first_time_setup(self):
        """é¦–æ¬¡ä½¿ç”¨å¼•å¯¼"""
        print("\n=== æ¬¢è¿ä½¿ç”¨æ€§åˆ«åˆ»æ¿å°è±¡åˆ†æå·¥å…· ===")
        print("è¿™æ˜¯æ‚¨é¦–æ¬¡ä½¿ç”¨æœ¬å·¥å…·ï¼Œè¯·æŒ‰ç…§æç¤ºè¿›è¡Œé…ç½®ï¼š")
        
        # è·å–ç”¨æˆ·è‡ªå®šä¹‰çš„ç”·æ€§å…³é”®è¯
        print("\nè¯·è¾“å…¥é¢å¤–çš„ç”·æ€§ç›¸å…³è¯æ±‡ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ï¼‰ï¼š")
        print(f"å½“å‰é»˜è®¤å€¼ï¼š{' '.join(self.male_keywords)}")
        custom_male = input().strip()
        if custom_male:
            self.male_keywords.update(custom_male.split())
        
        # è·å–ç”¨æˆ·è‡ªå®šä¹‰çš„å¥³æ€§å…³é”®è¯
        print("\nè¯·è¾“å…¥é¢å¤–çš„å¥³æ€§ç›¸å…³è¯æ±‡ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ï¼‰ï¼š")
        print(f"å½“å‰é»˜è®¤å€¼ï¼š{' '.join(self.female_keywords)}")
        custom_female = input().strip()
        if custom_female:
            self.female_keywords.update(custom_female.split())
        
        # è·å–ç”¨æˆ·è‡ªå®šä¹‰çš„åœç”¨è¯
        print("\nè¯·è¾“å…¥é¢å¤–çš„åœç”¨è¯ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ï¼‰ï¼š")
        print(f"å½“å‰é»˜è®¤å€¼ï¼š{' '.join(self.stopwords)}")
        custom_stopwords = input().strip()
        if custom_stopwords:
            self.stopwords.update(custom_stopwords.split())
        
        # ä¿å­˜é…ç½®
        config_path = os.path.join(os.path.dirname(__file__), 'config.json')
        self.save_config(config_path)
        print(f"\né…ç½®å·²ä¿å­˜åˆ°ï¼š{config_path}")
        print("ä¸‹æ¬¡ä½¿ç”¨æ—¶å°†è‡ªåŠ¨åŠ è½½æ­¤é…ç½®ã€‚")
    
    def preprocess_text(self, text):
        """é¢„å¤„ç†æ–‡æœ¬"""
        try:
            # åˆ†è¯å’Œè¯æ€§æ ‡æ³¨
            words = pseg.cut(text)
            return [(word, flag) for word, flag in words]
        except Exception as e:
            logger.error(f"æ–‡æœ¬é¢„å¤„ç†å¤±è´¥: {e}")
            return []
    
    def extract_adjectives(self, words, target_word):
        """æå–å½¢å®¹è¯"""
        try:
            adjectives = []
            for i, (word, pos) in enumerate(words):
                if word == target_word:
                    # å‘å‰æŸ¥æ‰¾
                    for j in range(max(0, i - self.window_size), i):
                        if words[j][1] in self.adjective_pos_tags:
                            adjectives.append(words[j][0])
                    # å‘åæŸ¥æ‰¾
                    for j in range(i + 1, min(len(words), i + self.window_size + 1)):
                        if words[j][1] in self.adjective_pos_tags:
                            adjectives.append(words[j][0])
            return adjectives
        except Exception as e:
            logger.error(f"æå–å½¢å®¹è¯å¤±è´¥: {e}")
            return []
    
    def find_cooccurrences(self, words):
        """æŸ¥æ‰¾æ€§åˆ«å…³é”®è¯çš„å…±ç°"""
        try:
            cooccurrences = []
            for i, (word, _) in enumerate(words):
                if word in self.male_keywords or word in self.female_keywords:
                    # è·å–ä¸Šä¸‹æ–‡çª—å£
                    start = max(0, i - self.window_size)
                    end = min(len(words), i + self.window_size + 1)
                    context = [w for w, _ in words[start:end]]
                    cooccurrences.append((word, context))
            return cooccurrences
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾å…±ç°å¤±è´¥: {e}")
            return []
    
    def analyze(self, text):
        """åˆ†ææ–‡æœ¬ä¸­çš„æ€§åˆ«åˆ»æ¿å°è±¡"""
        try:
            # é¢„å¤„ç†æ–‡æœ¬
            words = self.preprocess_text(text)
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress = ProgressBar(len(words), prefix='åˆ†ææ–‡æœ¬', suffix='', length=40)
            
            # ç»Ÿè®¡æ€§åˆ«å…³é”®è¯çš„å½¢å®¹è¯
            male_adjectives = []
            female_adjectives = []
            
            for i, (word, _) in enumerate(words):
                if word in self.male_keywords:
                    adjectives = self.extract_adjectives(words, word)
                    male_adjectives.extend(adjectives)
                elif word in self.female_keywords:
                    adjectives = self.extract_adjectives(words, word)
                    female_adjectives.extend(adjectives)
                
                # æ›´æ–°è¿›åº¦æ¡ï¼ˆæ¯10ä¸ªè¯æ›´æ–°ä¸€æ¬¡ï¼Œä»¥é¿å…è¿‡å¤šIOæ“ä½œï¼‰
                if i % 10 == 0 or i == len(words) - 1:
                    progress.update(i + 1)
            
            # ç»Ÿè®¡è¯é¢‘
            male_counter = Counter(male_adjectives)
            female_counter = Counter(female_adjectives)
            
            return male_counter, female_counter
        except Exception as e:
            logger.error(f"åˆ†ææ–‡æœ¬å¤±è´¥: {e}")
            return Counter(), Counter()
    
    def visualize(self, male_counter, female_counter, output_dir):
        """å¯è§†åŒ–åˆ†æç»“æœ"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # æ˜¾ç¤ºå¯è§†åŒ–è¿›åº¦
            print("\nå¼€å§‹ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
            progress = ProgressBar(4, prefix='ç”Ÿæˆå¯è§†åŒ–', suffix='', length=40)
            
            # ç”Ÿæˆè¯äº‘
            male_wordcloud = WordCloud(
                font_path=self.font_path,
                width=800,
                height=400,
                background_color='white'
            ).generate_from_frequencies(male_counter)
            progress.update()
            
            female_wordcloud = WordCloud(
                font_path=self.font_path,
                width=800,
                height=400,
                background_color='white'
            ).generate_from_frequencies(female_counter)
            progress.update()
            
            # ä¿å­˜è¯äº‘å›¾
            plt.figure(figsize=(10, 5))
            plt.subplot(1, 2, 1)
            plt.imshow(male_wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.title('ç”·æ€§å½¢å®¹è¯è¯äº‘')
            
            plt.subplot(1, 2, 2)
            plt.imshow(female_wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.title('å¥³æ€§å½¢å®¹è¯è¯äº‘')
            
            plt.savefig(os.path.join(output_dir, 'wordcloud.png'))
            plt.close()
            progress.update()
            
            # ç”Ÿæˆå¯¹æ¯”æŸ±çŠ¶å›¾å’ŒCSVæŠ¥å‘Š
            plt.figure(figsize=(12, 6))
            male_words = list(male_counter.keys())
            male_counts = list(male_counter.values())
            female_words = list(female_counter.keys())
            female_counts = list(female_counter.values())
            
            # è·å–æ‰€æœ‰å‡ºç°çš„å½¢å®¹è¯
            all_words = list(set(male_words + female_words))
            
            if all_words:  # ç¡®ä¿æœ‰å½¢å®¹è¯
                x = np.arange(len(all_words))
                width = 0.35
                
                plt.bar(x - width/2, [male_counter.get(word, 0) for word in all_words], width, label='ç”·æ€§')
                plt.bar(x + width/2, [female_counter.get(word, 0) for word in all_words], width, label='å¥³æ€§')
                
                plt.xlabel('å½¢å®¹è¯')
                plt.ylabel('é¢‘æ¬¡')
                plt.title('æ€§åˆ«å½¢å®¹è¯ä½¿ç”¨å¯¹æ¯”')
                plt.xticks(x, all_words, rotation=45)
                plt.legend()
                
                plt.tight_layout()
                plt.savefig(os.path.join(output_dir, 'comparison.png'))
                plt.close()
            
            # ç”ŸæˆCSVæŠ¥å‘Š
            df = pd.DataFrame({
                'å½¢å®¹è¯': all_words,
                'ç”·æ€§é¢‘æ¬¡': [male_counter.get(word, 0) for word in all_words],
                'å¥³æ€§é¢‘æ¬¡': [female_counter.get(word, 0) for word in all_words]
            })
            df.to_csv(os.path.join(output_dir, 'report.csv'), index=False, encoding='utf-8-sig')
            progress.update()
            
            print(f"\nâœ… åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¯è§†åŒ–ç»“æœå¤±è´¥: {e}")
            print(f"\nâŒ ç”Ÿæˆå¯è§†åŒ–ç»“æœå¤±è´¥: {e}")

def analyze_file(input_file, output_dir, config_file=None):
    """åˆ†æå•ä¸ªæ–‡ä»¶"""
    try:
        # åˆ›å»ºåˆ†æå™¨
        analyzer = GenderStereotypeAnalyzer(config_file)
        
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(input_file) / 1024  # KB
        print(f"\nğŸ“„ æ­£åœ¨åˆ†ææ–‡ä»¶: {os.path.basename(input_file)} ({file_size:.2f} KB)")
        
        # è¯»å–æ–‡æœ¬
        with open(input_file, 'r', encoding='utf-8') as f:
            text = f.read()
        
        # æ˜¾ç¤ºæ–‡æœ¬ä¿¡æ¯
        print(f"ğŸ“Š æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # åˆ†ææ–‡æœ¬
        male_counter, female_counter = analyzer.analyze(text)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ åˆ†æç»“æœç»Ÿè®¡:")
        print(f"  - è¯†åˆ«å‡ºç”·æ€§ç›¸å…³è¯æ±‡: {sum(male_counter.values())} ä¸ª")
        print(f"  - è¯†åˆ«å‡ºå¥³æ€§ç›¸å…³è¯æ±‡: {sum(female_counter.values())} ä¸ª")
        
        # å¯è§†åŒ–ç»“æœ
        analyzer.visualize(male_counter, female_counter, output_dir)
        
    except Exception as e:
        logger.error(f"åˆ†ææ–‡ä»¶å¤±è´¥: {e}")
        print(f"\nâŒ åˆ†ææ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)

def analyze_directory(input_dir, output_dir, config_file=None):
    """åˆ†ææ•´ä¸ªç›®å½•"""
    try:
        # è·å–æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶
        text_files = glob.glob(os.path.join(input_dir, '*.txt'))
        
        if not text_files:
            logger.warning(f"åœ¨ç›®å½• {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬æ–‡ä»¶")
            print(f"\nâ— è­¦å‘Š: åœ¨ç›®å½• {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬æ–‡ä»¶")
            return
        
        # æ˜¾ç¤ºç›®å½•ä¿¡æ¯
        print(f"\nğŸ“ æ­£åœ¨åˆ†æç›®å½•: {input_dir}")
        print(f"ğŸ“š å‘ç° {len(text_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶")
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress = ProgressBar(len(text_files), prefix='åˆ†ææ–‡ä»¶', suffix='', length=40)
        
        # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºå•ç‹¬çš„è¾“å‡ºç›®å½•
        for i, text_file in enumerate(text_files):
            filename = os.path.basename(text_file)
            file_output_dir = os.path.join(output_dir, os.path.splitext(filename)[0])
            
            # æ›´æ–°è¿›åº¦æ¡çš„åç¼€æ˜¾ç¤ºå½“å‰å¤„ç†çš„æ–‡ä»¶
            progress.suffix = f"- {filename}"
            progress.update(i + 1)
            
            # åˆ†ææ–‡ä»¶
            analyze_file(text_file, file_output_dir, config_file)
            
        print(f"\nâœ… ç›®å½•åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
            
    except Exception as e:
        logger.error(f"åˆ†æç›®å½•å¤±è´¥: {e}")
        print(f"\nâŒ åˆ†æç›®å½•å¤±è´¥: {e}")
        sys.exit(1)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ€§åˆ«åˆ»æ¿å°è±¡åˆ†æå·¥å…·')
    parser.add_argument('input', help='è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•çš„è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºç›®å½•çš„è·¯å¾„', default='output')
    parser.add_argument('-c', '--config', help='é…ç½®æ–‡ä»¶çš„è·¯å¾„')
    parser.add_argument('--setup', action='store_true', help='é‡æ–°è¿è¡Œé¦–æ¬¡ä½¿ç”¨å¼•å¯¼')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input):
        logger.error(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = GenderStereotypeAnalyzer(args.config)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿è¡Œé¦–æ¬¡ä½¿ç”¨å¼•å¯¼
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    if args.setup or not os.path.exists(config_path):
        analyzer.first_time_setup()
    
    # æ ¹æ®è¾“å…¥ç±»å‹é€‰æ‹©åˆ†æå‡½æ•°
    if os.path.isfile(args.input):
        analyze_file(args.input, args.output, args.config)
    else:
        analyze_directory(args.input, args.output, args.config)

if __name__ == '__main__':
    main() 